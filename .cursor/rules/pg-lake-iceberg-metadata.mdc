---
description: pg_lake dynamic Iceberg metadata resolution from Snowflake
globs: pg_lake/**
alwaysApply: false
---

# pg_lake Iceberg Metadata Resolution

pg_lake dynamically fetches Iceberg metadata locations from Snowflake at setup time. This ensures foreign tables always point to the latest Iceberg snapshot.

## Data Flow Architecture

```
Snowflake Postgres (OLTP)
        │
        │ POSTGRES_SYNC_TASK (5 min)
        ▼
Snowflake RAW tables
        │
        │ PG_LAKE_REFRESH_TASK (5 min)
        ▼
Iceberg tables → S3 → pg_lake
```

## How It Works

### 1. Query Snowflake for Current Metadata Paths

`setup.sh` uses `SYSTEM$GET_ICEBERG_TABLE_INFORMATION()` to get live metadata locations:

```sql
SELECT 
    'PRODUCT_REVIEWS' as table_name,
    PARSE_JSON(SYSTEM$GET_ICEBERG_TABLE_INFORMATION('AUTOMATED_INTELLIGENCE.PG_LAKE.PRODUCT_REVIEWS')):metadataLocation::STRING as metadata_location
UNION ALL
SELECT 
    'SUPPORT_TICKETS',
    PARSE_JSON(SYSTEM$GET_ICEBERG_TABLE_INFORMATION('AUTOMATED_INTELLIGENCE.PG_LAKE.SUPPORT_TICKETS')):metadataLocation::STRING
```

### 2. Parse Response with Snow CLI

```bash
METADATA_JSON=$(snow sql -c "$SF_CONNECTION" --format json -q "$QUERY")
PRODUCT_REVIEWS_PATH=$(echo "$METADATA_JSON" | python3 -c "import sys,json; ...")
```

### 3. Generate `init-postgres.sql` Dynamically

The script generates fresh SQL with current S3 paths:

```sql
CREATE FOREIGN TABLE product_reviews()
SERVER pg_lake
OPTIONS (path '$PRODUCT_REVIEWS_PATH');
```

### 4. Restart Container

Container restarts with the fresh config to load updated foreign tables.

## Snowflake Refresh Task

`PG_LAKE_REFRESH_TASK` in `snowflake_export.sql` keeps Iceberg tables in sync:

- **Schedule**: Every 5 minutes
- **Operation**: MERGE (upsert) from `RAW.*` tables to `PG_LAKE.*` Iceberg tables
- **Tables**: `PRODUCT_REVIEWS`, `SUPPORT_TICKETS`

```sql
-- Check task status
SHOW TASKS LIKE 'PG_LAKE_REFRESH_TASK' IN SCHEMA PG_LAKE;

-- View task history
SELECT * FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY(TASK_NAME => 'PG_LAKE_REFRESH_TASK')) 
ORDER BY SCHEDULED_TIME DESC LIMIT 10;

-- Manual execution
EXECUTE TASK PG_LAKE_REFRESH_TASK;

-- Pause/Resume
ALTER TASK PG_LAKE_REFRESH_TASK SUSPEND;
ALTER TASK PG_LAKE_REFRESH_TASK RESUME;
```

Each MERGE creates a new Iceberg metadata version, which is why `setup.sh` must fetch fresh paths.

## Key Points

- **Never hardcode metadata paths** - they change with each Iceberg commit
- **Always run `setup.sh`** before using pg_lake to get fresh paths
- **Metadata location format**: `s3://bucket/path/to/metadata/<version>.metadata.json`
- **Task creates new metadata** - after each refresh, metadata path changes
- **Point to Iceberg metadata JSON** - NOT raw parquet files (preserves schema, snapshots)

See `pg_lake/README.md` for complete documentation: architecture, prerequisites, troubleshooting, and query examples.
