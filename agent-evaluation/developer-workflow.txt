====================================================
Developer Integration Workflow
====================================================

1. Instrument Your Application
Use the TruLens SDK to add observability to your Python application:

    python
    from trulens.core.otel.instrument import instrument
    from trulens.otel.semconv.trace import SpanAttributes

    @instrument(span_type=SpanAttributes.SpanType.RECORD_ROOT)
    def answer_query(self, query: str) -> str:
        context_str = self.retrieve_context(query)
        return self.generate_completion(query, context_str)

    @instrument(span_type=SpanAttributes.SpanType.RETRIEVAL)
    def retrieve_context(self, query: str) -> list:
        return self.retrieve(query)

2. Register and Evaluate
• Create a TruApp object to register your application in Snowflake
• Set up run configurations with datasets for evaluation
• Execute runs to generate traces and compute metrics like coherence, groundedness, context relevance, and answer relevance

3. Monitor Results
• View evaluation results, traces, and user feedback in Snowsight
• Access detailed logs showing prompts, responses, and errors
• Track cost and latency metrics automatically

4. Iterate and Improve
• Compare different LLM configurations and application versions
• Use LLM-as-a-judge approach for automated scoring
• Leverage continuous monitoring to refine agent behavior

This integrated approach allows you to systematically assess and improve AI agent performance while maintaining security and governance within Snowflake's platform.

====================================================
Debug Options
====================================================

Based on the Snowflake AI Observability documentation, here are my recommendations to resolve the issue where `run.start()` isn't working and the status remains `CREATED`:

## **Root Cause Analysis**
The error `'str' object has no attribute 'get'` in the evaluator suggests that the metrics computation is receiving string data when it expects a dictionary/object with a `.get()` method. This points to dataset formatting or attribute mapping issues.

## **Immediate Troubleshooting Steps**

### 1. **Verify Required Privileges**
Ensure your role has all required privileges:
- `CORTEX_USER` database role
- `AI_OBSERVABILITY_EVENTS_LOOKUP` application role  
- `CREATE EXTERNAL AGENT` privilege on the schema
- `CREATE TASK` privilege on the schema
- `EXECUTE TASK` global privilege

### 2. **Check Dataset Attribute Mapping**
The most likely cause is incorrect dataset column mapping. Verify your dataset columns are properly mapped to reserved attributes:
- `RECORD_ROOT.INPUT` - Input prompt to the LLM (string)
- `RECORD_ROOT.INPUT_ID` - Unique identifier (string) 
- `RETRIEVAL.QUERY_TEXT` - User query for RAG applications (string)
- `RECORD_ROOT.GROUND_TRUTH_OUTPUT` - Expected response (string)

### 3. **Validate Dataset Structure**
- Ensure your dataset is properly formatted as either a Snowflake table or pandas DataFrame
- Check that all required columns exist and contain the correct data types
- Verify no null values in critical columns

### 4. **Environment Configuration**
- Confirm `TRULENS_OTEL_TRACING=1` environment variable is set
- Verify TruLens package versions are 2.1.2 or later
- Ensure you're not running in a Snowflake Notebook (not supported)

## **Debugging Approach**

1. **Check Run Status**: Use `run.get_status()` to monitor the exact status

2. **Validate Application Registration**: Ensure the EXTERNAL AGENT object was created successfully during application registration

3. **Review Dataset Schema**: Double-check that your dataset follows the exact attribute naming conventions and data types

4. **Test with Minimal Dataset**: Try with a small, well-formed dataset to isolate the issue

The `CREATED` status indicates the run hasn't started the invocation process, which typically points to dataset or permission issues rather than the `run.start()` method itself.

====================================================
Additional Debug Options
====================================================

Since your setup checks out but you're not getting metrics output, this suggests the issue is in the **metrics computation phase** rather than the initial invocation. Here's what to investigate:

## **Key Issue: Missing Metrics Computation Step**

The most likely cause is that you need to **explicitly trigger metrics computation** after `run.start()` completes. Based on the documentation, the process requires two separate steps:

1. **Invocation**: `run.start()` (gets status to `INVOCATION_COMPLETED`)
2. **Computation**: `run.compute_metrics()` (separate step to actually compute metrics)

## **Immediate Action Items**

### 1. **Check Current Run Status**
```python
current_status = run.get_status()
print(f"Current status: {current_status}")
```

### 2. **Trigger Metrics Computation**
Once status is `INVOCATION_COMPLETED` or `INVOCATION_PARTIALLY_COMPLETED`, explicitly call:

```python
run.compute_metrics(metrics=[
    "coherence",
    "answer_relevance", 
    "groundedness",
    "context_relevance",
    "correctness"
])
```

### 3. **Verify Metric Names**
Ensure you're using correct snake_case naming:
- "Context Relevance" → `context_relevance`
- "Answer Relevance" → `answer_relevance`
- "Groundedness" → `groundedness`

## **Additional Troubleshooting**

### **Check Required Attributes for Metrics**
For `context_relevance`, ensure your dataset has:
- `RETRIEVAL.QUERY_TEXT`: User query 
- `RETRIEVAL.RETRIEVED_CONTEXTS`: Retrieved context (List[string])
- `RECORD_ROOT.OUTPUT`: LLM-generated response

### **Monitor Computation Progress**
```python
# Check if computation started
status = run.get_status()
# Should show COMPUTATION_IN_PROGRESS then COMPLETED
```

### **Warehouse Resource Check**
Since metrics computation uses warehouse resources, ensure:
- Your warehouse is running and accessible
- Sufficient compute resources available
- No resource constraints blocking the computation

The key insight is that **metrics computation is a separate, explicit step** after invocation completes. The `'str' object has no attribute 'get'` error likely occurs when the system tries to compute metrics without proper attribute mapping or when the computation step hasn't been triggered correctly.

====================================================
Additional Notes
====================================================

For AI Observability evaluation, you should **use the TruLens SDK to instrument your application**, regardless of whether you're calling Cortex Agents via REST API or SDK. Here's why:

## **Recommended Approach: TruLens SDK Instrumentation**

**Use TruLens SDK with `@instrument()` decorators** to wrap your application logic, whether it calls:
- Cortex Agents REST API directly
- Snowflake Cortex Agent SDK  
- Any other LLM/AI service

## **Key Architectural Principle**

AI Observability works at the **application layer**, not the service layer. It can instrument applications that "run in any environment (such as Snowflake, cloud, or on-premises)" - the focus is on **your application's functions**, not the underlying service calls.

## **Implementation Strategy**

```python
from trulens.core.otel.instrument import instrument

@instrument()
def query_agent(self, query: str) -> str:
    # This could call either:
    # 1. Cortex Agents REST API directly
    # 2. Cortex Agent SDK
    # 3. Any other agent/LLM service
    response = your_agent_call(query)
    return response
```

## **Why This Approach Works Best**

1. **Consistency**: Same instrumentation approach regardless of underlying service
2. **Flexibility**: Can capture traces from mixed architectures (REST + SDK + other services)
3. **Comprehensive Tracing**: Captures your application's orchestration logic, not just individual service calls
4. **Future-proof**: Works as you evolve from REST API to SDK or vice versa

## **Bottom Line**

The choice between REST API vs SDK for Cortex Agents is orthogonal to AI Observability setup. Focus on **instrumenting your application functions** with TruLens SDK - this captures the complete evaluation context regardless of how you interact with the underlying agent services.

This gives you consistent observability and evaluation capabilities across your entire AI application stack.

====================================================
Critical Diagnostics
====================================================

This indicates a **fundamental instrumentation issue** - your application functions aren't being traced, so no invocation data is being recorded. Here are the specific debugging steps:

### 1. **Verify TruLens Connection & Instrumentation**
```python
# Check if TRULENS_OTEL_TRACING is properly set
import os
print(f"TRULENS_OTEL_TRACING: {os.environ.get('TRULENS_OTEL_TRACING')}")

# Verify TruLens is connecting to Snowflake
from trulens.connectors.snowflake import SnowflakeConnector
connector = SnowflakeConnector()
print(f"Connector status: {connector}")
```

### 2. **Check EXTERNAL AGENT Object Exists**
```sql
-- Verify your application was registered correctly
SHOW EXTERNAL AGENTS LIKE '%your_app_name%';

-- Check if you have USAGE privileges
DESCRIBE EXTERNAL AGENT your_db.your_schema.your_app_name;
```

### 3. **Verify Application Instrumentation**
The issue suggests your functions aren't properly instrumented. Ensure you have:

```python
from trulens.core.otel.instrument import instrument

@instrument()  # This decorator is REQUIRED
def your_agent_function(query: str) -> str:
    # Your agent logic here
    result = call_your_agent(query)
    return result
```

### 4. **Check Event Table for Any Data**
```sql
-- Check if ANY traces are being recorded
SELECT COUNT(*) FROM SNOWFLAKE.LOCAL.AI_OBSERVABILITY_EVENTS;

-- If count > 0, check for your specific application
SELECT * FROM SNOWFLAKE.LOCAL.AI_OBSERVABILITY_EVENTS 
WHERE APPLICATION_NAME = 'your_app_name' 
LIMIT 5;
```

## **Most Likely Root Causes**

### **Issue 1: Missing @instrument() Decorators**
- **run.start()** completes but no invocations are recorded
- This means your application functions aren't decorated with `@instrument()`
- The system can't capture traces without proper instrumentation

### **Issue 2: EXTERNAL AGENT Registration Problem**
- Check if the EXTERNAL AGENT object was created successfully during app registration
- Verify you have **USAGE** privileges on the EXTERNAL AGENT object

### **Issue 3: TruLens Connection Failure**
- Even with `TRULENS_OTEL_TRACING=1`, the connection to Snowflake might be failing
- Check your Snowflake connection parameters in the TruLens configuration

## **Immediate Action Plan**

1. **Add missing @instrument() decorators** to all functions that should be traced
2. **Verify EXTERNAL AGENT object exists** and you have proper access
3. **Test with minimal instrumented function** to confirm trace capture works
4. **Check AI_OBSERVABILITY_EVENTS table** for any data

The key insight: **run.start() executes your dataset loop, but without proper instrumentation, no traces are generated**, so the status never progresses from CREATED.

=========================================================================================
Warning: Cannot explicitly set 'record_root' span type, setting to 'unknown'." 
=========================================================================================

This warning means that **TruLens automatically determines which function should be the `RECORD_ROOT` span** and you cannot manually override this assignment.

## **What's Happening**

The `RECORD_ROOT` span type is special - it represents "the main function in your application" and **TruLens automatically assigns this designation** to what it considers the top-level entry point of your application during evaluation runs.

## **Why This Occurs**

When you try to explicitly set:
```python
@instrument(span_type=SpanAttributes.SpanType.RECORD_ROOT)
def my_function():
    # ...
```

TruLens overrides this because it needs to control which function serves as the root span for proper trace hierarchy and metrics computation.

## **What You Should Do**

**Use `RECORD_ROOT` span type in the documentation examples for reference, but in practice:**

1. **Let TruLens auto-assign RECORD_ROOT** - don't explicitly set it
2. **Use specific span types** for component functions:
   ```python
   @instrument(span_type=SpanAttributes.SpanType.RETRIEVAL)
   def retrieve_context(self, query: str) -> list:
       return self.retrieve(query)

   @instrument(span_type=SpanAttributes.SpanType.GENERATION)  
   def generate_completion(self, query: str, context_str: list) -> str:
       return response

   @instrument()  # Let TruLens assign RECORD_ROOT automatically
   def answer_query(self, query: str) -> str:
       context_str = self.retrieve_context(query)
       return self.generate_completion(query, context_str)
   ```

## **Bottom Line**

**This is just a warning, not an error.** Your instrumentation will still work - TruLens is simply telling you it's managing the `RECORD_ROOT` assignment automatically. Focus on properly instrumenting your component functions with `RETRIEVAL` and `GENERATION` span types where appropriate.

The `RECORD_ROOT` will be assigned to whichever function TruLens determines is the main entry point during the evaluation run.

====================================================
ACTUAL ROOT CAUSE IDENTIFIED (2025-11-19)
====================================================

After extensive debugging, the actual problem has been identified:

## **The Problem**
- `run.start()` completes successfully ✓
- Instrumented functions execute ✓
- Spans are generated with correct attributes ✓
- `TruLensSnowflakeSpanExporter.export()` returns SUCCESS ✓
- **BUT: The protobuf file is NOT being uploaded to the Snowflake stage ✗**
- Result: No traces in AI_OBSERVABILITY_EVENTS table, run status stays CREATED

## **Evidence**
1. Created stage manually: `CREATE STAGE SNOWFLAKE_INTELLIGENCE.AGENTS.trulens_spans`
2. After running evaluation: `LIST @SNOWFLAKE_INTELLIGENCE.AGENTS.trulens_spans` returns 0 files
3. Calling `SYSTEM$EXECUTE_AI_OBSERVABILITY_RUN` manually fails with internal error because no file exists

## **Root Cause**
The `_upload_temp_file_to_stage()` method in TruLens is failing silently. The export process:
1. Creates a temporary protobuf file with spans ✓
2. Attempts to upload to `@DB.SCHEMA.trulens_spans/filename.gz` ✗ (FAILS HERE)
3. Returns SUCCESS anyway (error handling issue)
4. Attempts to call `SYSTEM$EXECUTE_AI_OBSERVABILITY_RUN` SPROC
5. SPROC fails with internal error because file doesn't exist
6. But this failure is also caught and ignored ("Not returning failure here since the export was technically a success")

## **What This Means**
The instrumentation, OTEL setup, span generation - all of that is working correctly. The issue is specifically with the file upload mechanism from TruLens to the Snowflake stage. This is likely a TruLens SDK bug or configuration issue with how it uploads files to Snowflake stages.

## **Next Steps**
1. Check TruLens version - may need upgrade or downgrade
2. Look for known issues with TruLens stage upload
3. Try manual workaround by directly uploading protobuf files
4. Contact Snowflake support about TruLens + AI Observability integration

---

SYSTEM$EXECUTE_AI_OBSERVABILITY_RUN                                                                                                                        

What It Is                                                                                                                                                 

 • System-level stored procedure (built into Snowflake, not user-created)                                                                                  
 • Part of Snowflake's AI Observability infrastructure                                                                                                     
 • Not publicly documented (internal system function)                                                                                                      
 • Managed by Snowflake, accessed via AI_OBSERVABILITY_EVENTS_LOOKUP or AI_OBSERVABILITY_ADMIN application roles                                           

When It's Used                                                                                                                                             

Called by TruLens SDK after span files are uploaded to a Snowflake stage. It:                                                                              

 1 Reads protobuf files from the specified stage location                                                                                                  
 2 Parses the OpenTelemetry spans                                                                                                                          
 3 Writes them to SNOWFLAKE.LOCAL.AI_OBSERVABILITY_EVENTS table                                                                                            
 4 Updates the run status (CREATED → INVOCATION_IN_PROGRESS → INVOCATION_COMPLETED)                                                                        
 5 Triggers background tasks for metric computation                                                                                                        

Parameters (from TruLens source)                                                                                                                           

                                                                                                                                                           
 CALL SYSTEM$EXECUTE_AI_OBSERVABILITY_RUN(                                                                                                                 
     OBJECT_CONSTRUCT(                                                                                                                                     
         'object_name', 'DB.SCHEMA.AGENT_NAME',     -- EXTERNAL AGENT FQN (uppercase)                                                                      
         'object_type', 'External Agent',                                                                                                                  
         'object_version', 'v1'                      -- Version name                                                                                       
     ),                                                                                                                                                    
     OBJECT_CONSTRUCT(                                                                                                                                     
         'run_name', 'my_run_20251119'               -- Run identifier                                                                                     
     ),                                                                                                                                                    
     OBJECT_CONSTRUCT(                                                                                                                                     
         'type', 'stage_file',                       -- Source type                                                                                        
         'stage_file_path', '@DB.SCHEMA.trulens_spans/file.pb.gz',  -- Stage path                                                                          
         'input_record_count', 3                     -- Number of inputs                                                                                   
     ),                                                                                                                                                    
     ARRAY_CONSTRUCT(),                              -- Empty array (unknown purpose)                                                                      
     ARRAY_CONSTRUCT('INGESTION_MULTIPLE_BATCHES')  -- Evaluation phase                                                                                    
 )                                                                                                                                                         
                                                                                                                                                           

The Bug                                                                                                                                                    

TruLens creates the file in the wrong place:                                                                                                               

 1 Uploads to: TEMP stage trulens_spans (session-scoped, temporary)                                                                                        
 2 SPROC expects: Permanent stage @DB.SCHEMA.trulens_spans/file.gz                                                                                         
 3 Result: SPROC can't find file → fails with internal error → no traces recorded              
